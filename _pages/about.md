---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<p style="text-align:justify">
I am a Ph.D. student inÂ <a href="https://exertiongameslab.org/">Exertion games Lab</a>Â supervised by Prof.Â <a href="https://www.florianfloydmueller.com/">Florian 'Floyd' Mueller</a>Â working on Human-Food Interaction (Secondary Supervisor: Dr.Â <a href="https://samithaelvitigala.com/">Don Samitha Elvitigala</a>) at Monash University, Australia. My research interest lies in the intersection of technology, design and interaction. Currently, I am towards on designing interactive system to enrich culinary creativity, and exploring embeding digital contents into our daily eating.
</p>

<h2>My research interests</h2>
<p style="text-align:justify">
Human-Computer Interaction, Extended Reality, Interactive System, Deep Learning, Computer Vision, Generative AI, etc.
</p>

<h2>News</h2>
<ul>
<li><p style="text-align:justify"><b>05/2024:</b> I will attend <b>ACM CHI 2024</b>! See you in Hawaii!ðŸ˜Š</p></li>
<li><p style="text-align:justify"><b>03/2024:</b> Our two <b>ACM CHI 2024</b> late-breaking works have been accepted! Thanks to all the co-authors!</p></li>
<li><p style="text-align:justify"><b>09/2023:</b> I will join <b>Exertion Games Lab</b> at Monash University as a Ph.D. student. Another new journey strats!ðŸŽ‰</p></li>
</ul>

<h2>Full Paper Publications</h2>
<table style="border-collapse: collapse; border: none;">
<colgroup>
<col width="15%" />
<col width="85%" />
</colgroup>

<tbody style="border: none;">

<tr>
<td style="border: none;"><img src="/images/challenges.png" width="250"></td>
<td markdown="span" style="border: none; text-align:justify"><a href="https://www.sciencedirect.com/science/article/pii/S1071581923002069" target="_blank">**Grand challenges in human-food interaction**</a><br>Florian â€˜Floydâ€™ Mueller, Marianna Obrist, Ferran Altarriba Bertran, Neharika Makam, Soh Kim, Christopher Dawes, Patrizia Marti, Maurizio Mancini, Eleonora Ceccaldi, Nandini Pasumarthy, Sahej Claire, Kyung seo Jung, Jialin Deng, JÃ¼rgen Steimle, Nadejda Krasteva, Matti Schwalk, Harald Reiterer, **Hongyue Wang**, Yan Wang<br>*International Journal of Human-Computer Studies* 2024<br><a href="../files/grand challenges.pdf" target="_blank">[paper]</a></td>
</tr>

<tr>
<td style="border: none;"><img src="/images/2023_ijhci.png" width="250"></td>
<td markdown="span" style="border: none; text-align:justify"><a href="https://www.tandfonline.com/doi/abs/10.1080/10447318.2023.2227823" target="_blank">**MRLab: Virtual Reality Fusion Smart Laboratory Based on Multimodal Fusion**</a><br>**Hongyue Wang**, Zhiquan Feng\*, Xiaohui Yang, Liran Zhou, Jinglan Tian, and Qingbei Guo<br>*International Journal of Human-Computer Interaction* 2023<br><a href="../files/MRLab.pdf" target="_blank">[paper]</a></td>
</tr>

<tr>
<td style="border: none;"><img src="/images/2023_robot.png" width="250"></td>
<td markdown="span" style="border: none; text-align:justify"><a href="https://www.tandfonline.com/doi/abs/10.1080/10447318.2023.2247606?journalCode=hihc20" target="_blank">**MIUIC: A Human-Computer Collaborative Multimodal Intention-Understanding Algorithm Incorporating Comfort Analysis**</a><br>Liran Zhou, Zhiquan Feng\*, **Hongyue Wang**, and Qingbei Guo<br>*International Journal of Human-Computer Interaction* 2023<br><a href="../files/MIUIC.pdf" target="_blank">[paper]</a></td>
</tr>

<tr>
<td style="border: none;"><img src="/images/glove2.png" width="250"></td>
<td markdown="span" style="border: none; text-align:justify"><a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/admt.202200549">**Multimodal Information Perception and Understanding: Application of Smart Glove in Virtual-Reality Fusion Chemistry Experiment Platform**</a><br>**Hongyue Wang**, Zhiquan Feng\*, and Xin Meng<br>*Advanced Materials Technologies* 2023<br><a href="../files/Multimodal Information Perception and Understandingï¼šApplication of Smart Glove in Virtual-Reality Fusion Chemistry Experiment Platform.pdf" target="_blank">[paper]</a><a href="https://youtu.be/8btwYEO1cd4" target="_blank">[video]</a></td>
</tr>

<tr>
<td style="border: none;"><img src="/images/glove1.png" width="250"></td>
<td markdown="span" style="border: none; text-align:justify"><a href="https://www.hindawi.com/journals/cin/2022/3545850/" target="_blank">**MFA: A Smart Glove with Multimodal Intent Sensing Capability**</a><br>**Hongyue Wang**, Zhiquan Feng\*, Jinglan Tian, and Xue Fan<br>*Computational Intelligence and Neuroscience* 2022<br><a href="../files/MFA.pdf" target="_blank">[paper]</a></td>
</tr>

<tr>
<td style="border: none;"><img src="/images/glove3.jpg" width="250"></td>
<td markdown="span" style="border: none; text-align:justify"><a href="https://link.springer.com/chapter/10.1007/978-981-19-4546-5_32">**Research on the Structure and Key Algorithms of Smart Gloves Oriented to Middle School Experimental Scene Perception**</a><br>**Hongyue Wang**, Xin Meng, and Zhiquan Feng\*<br>*ChineseCSCW '21: Computer Supported Cooperative Work and Social Computing*<br><a href="../files/Research on the Structure and Key Algorithms of Smart Gloves Oriented to Middle School Experimental Scene Perception.pdf" target="_blank">[paper]</a></td>
</tr>
</tbody>
</table>



<h2>Workshop Papers, Extended Abstracts, and Doctoral Consortium</h2>
<table style="border-collapse: collapse; border: none;">
<colgroup>
<col width="15%" />
<col width="85%" />
</colgroup>

<tbody style="border: none;">

<tr>
<td style="border: none;" markdown="span"><img src="/images/pic2eat2.jpg" width="250"></td>
<td markdown="span" style="border: none; text-align:justify"><a href="https://doi.org/10.1145/3613905.3651082" target="_blank">**pic2eat: Facilitating Social Ice-breaking through Collaborative Design of 3D Printed Appetizer**</a><br>**Hongyue Wang**, Jialin Deng, Aravind Mohan, Yinyi Li, Hao Peng, Linjia He, Don Samitha Elvitigala, Florian 'Floyd' Mueller<br>*ACM CHI Conference on Human Factors in Computing Systems __(CHI 2024 Extended Abstract)__*<br><a href="../files/pic2eat.pdf" target="_blank">[paper]</a><a href="https://www.youtube.com/watch?v=d0GZcocqnV0" target="_blank">[video]</a></td>
</tr>

<tr>
<td style="border: none;"><img src="/images/penlab2.jpg" width="250"></td>
<td markdown="span" style="border: none; text-align:justify"><a href="https://dl.acm.org/doi/10.1145/3613905.3650789" target="_blank">**PenLab: Towards Understanding of Active Collaboration for Solid Geometry Teaching**</a><br>Dehui Kong, **Hongyue Wang**, Sijie Zhou, Hong Cui, Zhiquan Feng<br>*ACM CHI Conference on Human Factors in Computing Systems __(CHI 2024 Extended Abstract)__*<br><a href="../files/penlab.pdf" target="_blank">[paper]</a><a href="https://www.youtube.com/watch?v=KzXrsdY8Xhw" target="_blank">[video]</a></td>
</tr>

<tr>
<td style="border: none;"><img src="/images/ar-cyclying.jpeg" width="250"></td>
<td markdown="span" style="border: none; text-align:justify"><a href="https://dl.acm.org/doi/abs/10.1145/3656156.3663699" target="_blank">**Pedalling into the Future: Towards Enhancing Cycling Experience Using Augmented Reality**</a><br>Linjia He, **Hongyue Wang**, Sarah Goodwin, Benjamin Tag, Don Samitha Elvitigala<br>*ACM Designing Interactive Systems Conference __(DIS 2024 Extended Abstract)__*<br><a href="../files/Pedalling into the Future.pdf" target="_blank">[paper]</a></td>
</tr>



</tbody>
</table>

<h2>Academic Service</h2>
<ul>
<li><p style="text-align:justify"><b>2025:</b>Paper reviewer: CHI 2025</p></li>
<li><p style="text-align:justify"><b>2024:</b>Paper reviewer: IJHCI (International journal of Human-computer Interaction), DIS 2024, CHI 2024 Late-breaking work</p></li>
</ul>

<h2>Selected Honors and Grants</h2>
<ul>
<li><p style="text-align:justify"><b>05/2023:</b> Monash University-China Scholarship Council (CSC) Joint Scholarship</p></li>
<li><p style="text-align:justify"><b>05/2023:</b> National Scholarship for Chinese University Students (Top 1%)</p></li>
</ul>
